---
title: "DDPM 논문 이해하기 (1편): Diffusion 첫걸음"
date: 2024-09-17 21:45:00 +0900
categories: [Computer Vision, Generative Model]
tags: [markov chain, diffusion]     # TAG names should always be lowercase
author: moon
math: true
toc: true
---

[[PDF](https://arxiv.org/pdf/2006.11239)][[Code](https://github.com/hojonathanho/diffusion)]

최근 인공지능(AI) 분야에서 **생성 모델**의 발전이 눈부십니다. 특히 **생성적 적대 신경망(GAN)**, **변분 오토인코더(VAE)**, **오토리그레시브 모델** 같은 모델들은 이미지를 생성하는 데 탁월한 성과를 보여주었고, 이를 통해 우리는 AI가 만들어내는 멋진 이미지와 음악 샘플들을 접할 수 있었습니다. 이런 모델들이 점차 복잡한 데이터를 처리하고 높은 품질의 결과물을 만들어내고 있는 상황에서, 최근 주목받는 또 다른 모델이 있습니다. 바로 **확산 확률 모델(Diffusion Probabilistic Models, 이하 확산 모델)**입니다.

이 글에서는 확산 모델에 대한 핵심 내용을 소개하고, 이 모델이 어떻게 작동하는지, 그리고 왜 주목받는지 설명하겠습니다.

<br>

## 1. 확산 모델이란?

확산 모델은 데이터에 점진적으로 **노이즈**를 추가하는 과정과, 그 반대로 **노이즈를 제거하며 원본 데이터를 복원하는 과정**을 학습합니다. 조금 더 풀어 설명하자면, 이 모델은 **마코프 체인**이라는 개념을 사용합니다. 이는 일련의 상태가 단계적으로 변화하는 과정인데, 여기서는 데이터에 노이즈를 더하는 것이 그 변화 과정입니다. 노이즈가 계속해서 추가되면, 결국 원본 데이터는 소음에 묻혀 알아볼 수 없게 됩니다. 이후에는 이 과정을 역으로 수행해, 마치 퍼즐을 하나씩 맞춰가듯 데이터를 원래 상태로 복구해 나가는 것입니다.

![alt text](/assets/img/ddpm/graphical-model.png)

이 과정에서 **가우시안 노이즈**라는 통계적인 노이즈를 사용하고, 이를 기반으로 간단한 신경망 구조를 통해 학습이 이루어집니다. 쉽게 말해, 데이터를 점점 흐릿하게 만들었다가, 다시 선명하게 되돌리는 법을 배우는 것입니다. 이 점진적인 변화 과정을 통해 새로운 데이터 샘플을 생성할 수 있습니다.

<br>

## 2. 다른 생성 모델과의 차이점

많은 분들이 “확산 모델이 기존 GAN이나 VAE와는 뭐가 다를까?” 하고 궁금해하는데, 가장 큰 차이점은 **노이즈 제거 과정**을 학습한다는 점입니다. GAN이나 VAE는 주로 이미지나 데이터를 한 번에 생성하거나 특정 패턴을 학습하는 데 중점을 둔다면, 확산 모델은 **점진적인 변화**를 바탕으로 샘플을 만들어냅니다.

확산 모델은 상대적으로 정의하기 쉽고 학습 속도가 빠르다는 장점을 가지고 있지만, 과거에는 고품질의 샘플을 생성할 수 있다는 증거가 충분하지 않았습니다. 하지만 최근 연구들은 확산 모델이 GAN이나 다른 모델들보다 더 나은 품질의 이미지를 생성할 수 있음을 보여주고 있습니다. 즉, 이 모델이 가진 가능성은 이제 막 증명되기 시작한 셈입니다.

<br>

## 3. 확산 모델의 또 다른 특징: 노이즈 제거 스코어 매칭

또 하나 흥미로운 점은, 확산 모델이 **노이즈 제거 스코어 매칭(Denoising Score Matching)**과 매우 유사하다는 사실입니다. 학습 중에 데이터에 추가되는 여러 단계의 노이즈를 처리하며, 각 단계에서의 노이즈를 제거하는 방법을 익히게 됩니다. 이 과정은 결국 **가변적 랑주뱅 동역학(Annealed Langevin Dynamics)**이라는 기법과도 연결되며, 이를 통해 고품질의 샘플을 얻을 수 있습니다. 이 두 가지 개념은 수학적이지만, 쉽게 말하면 **데이터의 왜곡된 부분을 정확히 복원하는 방법을 계속해서 개선해나가는 과정**이라고 이해할 수 있습니다.

<br>

## 4. 한계점

확산 모델이 이미지 생성에서 뛰어난 성과를 보이고 있지만, 아직 해결해야 할 문제도 있습니다. 예를 들어, 다른 **우도 기반 모델**(Likelihood-based Models)에 비해 **로그 우도(log-likelihood)** 성능이 다소 낮다는 점이 있습니다. 이는 모델이 데이터를 얼마나 잘 설명하는지 평가하는 척도인데, 확산 모델은 이 부분에서 아직 경쟁력이 떨어집니다. 다만, 에너지 기반 모델이나 스코어 매칭 모델보다는 더 좋은 성과를 보인다는 점에서 의미가 있죠.

또한, 확산 모델이 생성하는 이미지의 많은 부분이 사람이 거의 인식하지 못하는 작은 디테일에 리소스를 많이 사용한다는 것도 하나의 단점입니다. 이를 극복하기 위해 연구자들은 이 과정을 **손실 압축(lossy compression)**의 관점에서 재해석하고 있으며, 샘플링 절차를 **progressive 디코딩** 방식으로 이해하는 등 다양한 개선책을 제시하고 있습니다.

<br>

## 5. 정리

이번 글에서는 **확산 확률 모델**의 개념을 간단하게 소개해드렸습니다. 이 모델은 점진적으로 노이즈를 더하고, 다시 그 노이즈를 제거하면서 데이터를 복원하는 독특한 방식으로 고품질의 샘플을 생성해냅니다. 기존의 생성 모델과는 다른 접근 방식을 취하고 있으며, 앞으로 더 많은 연구와 발전이 기대되는 분야입니다. 이어서 다음 글에서는 이 확산 모델의 학습 과정과 구체적인 동작 원리에 대해 더 자세히 다룰 예정입니다.